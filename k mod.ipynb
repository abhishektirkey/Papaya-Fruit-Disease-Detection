{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb9241c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kmodesNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading kmodes-0.12.2-py2.py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: numpy>=1.10.4 in c:\\users\\abhishek\\appdata\\roaming\\python\\python311\\site-packages (from kmodes) (1.25.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from kmodes) (1.3.0)\n",
      "Requirement already satisfied: scipy>=0.13.3 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from kmodes) (1.10.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from kmodes) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22.0->kmodes) (2.2.0)\n",
      "Installing collected packages: kmodes\n",
      "Successfully installed kmodes-0.12.2\n"
     ]
    }
   ],
   "source": [
    "pip install kmodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e50e7488",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABHISHEK\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkmodes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkmodes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KModes\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skimage.filters import sobel\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score,f1_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import canny\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.filters import prewitt_h,prewitt_v\n",
    "from skimage import io, color, util\n",
    "from kmodes.kmodes import KModes\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba6855ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Diseased\n",
      "Loaded category: Diseased successfully\n",
      "Loading category: Healthy\n",
      "Loaded category: Healthy successfully\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 19, cost: 1657167.0\n",
      "Run 1, iteration: 2/100, moves: 14, cost: 1653673.0\n",
      "Run 1, iteration: 3/100, moves: 0, cost: 1653673.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 11, cost: 1661003.0\n",
      "Run 2, iteration: 2/100, moves: 6, cost: 1657794.0\n",
      "Run 2, iteration: 3/100, moves: 1, cost: 1657794.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 29, cost: 1655517.0\n",
      "Run 3, iteration: 2/100, moves: 9, cost: 1653673.0\n",
      "Run 3, iteration: 3/100, moves: 0, cost: 1653673.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 4, cost: 1661910.0\n",
      "Run 4, iteration: 2/100, moves: 0, cost: 1661910.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 12, cost: 1661893.0\n",
      "Run 5, iteration: 2/100, moves: 2, cost: 1661870.0\n",
      "Run 5, iteration: 3/100, moves: 1, cost: 1661868.0\n",
      "Run 5, iteration: 4/100, moves: 0, cost: 1661868.0\n",
      "Best run was number 1\n",
      "x: (421, 4096)\n",
      "y: (421,)\n",
      "Splitted Successfully\n"
     ]
    }
   ],
   "source": [
    "# Define the categories\n",
    "Categories = ['Diseased', 'Healthy']\n",
    "\n",
    "flat_data_arr = []  # Input array\n",
    "target_arr = []  # Output array\n",
    "datadir = 'C:/Users/vivek/Downloads/Final Year Project/Project/DATA SET/'\n",
    "\n",
    "# Load images and prepare data for K-Modes clustering\n",
    "for category in Categories:\n",
    "    print(f'Loading category: {category}')\n",
    "    path = os.path.join(datadir, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path, img)\n",
    "        img_array = io.imread(img_path)\n",
    "        \n",
    "        # Convert the image to grayscale\n",
    "        img_gray = color.rgb2gray(img_array)\n",
    "        \n",
    "        # Resize the image to a desired size (e.g., 64x64)\n",
    "        img_resized = resize(img_gray, (64, 64))\n",
    "        \n",
    "        # Flatten the image\n",
    "        img_flattened = img_resized.flatten()\n",
    "        \n",
    "        # Convert pixel values to categorical data (just an example)\n",
    "        categorical_data = ['Pixel_'+str(i) for i in img_flattened]\n",
    "        \n",
    "        flat_data_arr.append(categorical_data)\n",
    "        target_arr.append(Categories.index(category))\n",
    "    \n",
    "    print(f'Loaded category: {category} successfully')\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(flat_data_arr, columns=[f'Pixel_{i}' for i in range(len(categorical_data))])\n",
    "df['Target'] = target_arr\n",
    "\n",
    "# Apply K-Modes clustering\n",
    "n_clusters = len(Categories)  # Number of clusters\n",
    "km = KModes(n_clusters=n_clusters, init='Huang', n_init=5, verbose=1)\n",
    "clusters = km.fit_predict(df.iloc[:, :-1])\n",
    "\n",
    "# Add cluster labels to the DataFrame\n",
    "df['Cluster'] = clusters\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x = df.iloc[:, :-2]  # Input data\n",
    "y = df['Cluster']  # Cluster labels as output\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=77, stratify=y)\n",
    "\n",
    "print(\"x:\", x.shape)\n",
    "print(\"y:\", y.shape)\n",
    "print('Splitted Successfully')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44924c24",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Pixel_1.0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 10\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeClassifier\n\u001b[0;32m      7\u001b[0m dtc\u001b[38;5;241m=\u001b[39mDecisionTreeClassifier(criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgini\u001b[39m\u001b[38;5;124m'\u001b[39m, splitter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest\u001b[39m\u001b[38;5;124m'\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m, min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, min_samples_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,   \n\u001b[0;32m      8\u001b[0m                            min_weight_fraction_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \n\u001b[0;32m      9\u001b[0m                            max_leaf_nodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  min_impurity_decrease\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ccp_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m \u001b[43mdtc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m y_pred_dtc\u001b[38;5;241m=\u001b[39mdtc\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03m'''print(\"The predicted Data is :\")\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03mprint(y_pred_dtc)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03mprint(\"The actual data is:\")\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03mprint(np.array(y_test))'''\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\New folder\\envs\\notebook\\lib\\site-packages\\sklearn\\tree\\_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    860\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \n\u001b[0;32m    862\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\New folder\\envs\\notebook\\lib\\site-packages\\sklearn\\tree\\_classes.py:186\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    184\u001b[0m check_X_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(dtype\u001b[38;5;241m=\u001b[39mDTYPE, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    185\u001b[0m check_y_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 186\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_separately\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcheck_X_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_y_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n\u001b[0;32m    190\u001b[0m     X\u001b[38;5;241m.\u001b[39msort_indices()\n",
      "File \u001b[1;32m~\\anaconda3\\New folder\\envs\\notebook\\lib\\site-packages\\sklearn\\base.py:579\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m check_X_params:\n\u001b[0;32m    578\u001b[0m     check_X_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdefault_check_params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_X_params}\n\u001b[1;32m--> 579\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_X_params)\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m check_y_params:\n\u001b[0;32m    581\u001b[0m     check_y_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdefault_check_params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params}\n",
      "File \u001b[1;32m~\\anaconda3\\New folder\\envs\\notebook\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\New folder\\envs\\notebook\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\New folder\\envs\\notebook\\lib\\site-packages\\pandas\\core\\generic.py:1998\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1996\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m   1997\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1998\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2000\u001b[0m         astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m   2001\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write()\n\u001b[0;32m   2002\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block\n\u001b[0;32m   2003\u001b[0m     ):\n\u001b[0;32m   2004\u001b[0m         \u001b[38;5;66;03m# Check if both conversions can be done without a copy\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m astype_is_view(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtypes\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(\n\u001b[0;32m   2006\u001b[0m             values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m   2007\u001b[0m         ):\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Pixel_1.0'"
     ]
    }
   ],
   "source": [
    "#DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "\n",
    "dtc=DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=25, min_samples_split=2, min_samples_leaf=1,   \n",
    "                           min_weight_fraction_leaf=0.0,max_features=None, random_state=None, \n",
    "                           max_leaf_nodes=None,  min_impurity_decrease=0.0, class_weight=None, ccp_alpha=0.0)\n",
    "dtc.fit(x_train,y_train)\n",
    "y_pred_dtc=dtc.predict(x_test)\n",
    "'''print(\"The predicted Data is :\")\n",
    "print(y_pred_dtc)\n",
    "print(\"The actual data is:\")\n",
    "print(np.array(y_test))'''\n",
    "print(f\"The model is {accuracy_score(y_pred_dtc,y_test)*100}% accurate\")\n",
    "\n",
    "\n",
    "accuracy_score(y_pred_dtc,y_test)\n",
    "print(classification_report(y_pred_dtc,y_test))\n",
    "#Build confusion matrix\n",
    "# Calculate the confusion matrix\n",
    "\n",
    "cf_matrix = confusion_matrix(y_true=y_test, y_pred=y_pred_dtc)\n",
    "\n",
    "#print(cf_matrix)\n",
    "#sns.heatmap(cf_matrix, annot=True)\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, fmt='.2%')\n",
    "a_dtc = accuracy_score(y_pred_dtc,y_test) \n",
    "p_dtc = precision_score(y_pred_dtc,y_test, average = 'weighted')\n",
    "r_dtc = recall_score(y_pred_dtc,y_test, average = 'weighted')\n",
    "print(\"Accuracy:\",round(a_dtc*100,2),\"%\")\n",
    "print(\"Precision:\",round(p_dtc*100,2),\"%\")\n",
    "print(\"Recall:\",round(r_dtc*100,2),\"%\")\n",
    "f1_dtc = f1_score(y_test, y_pred_dtc)\n",
    "print(\"f1_score:\",round(f1_dtc*100,2),\"%\")\n",
    "Training_accuracy_dtc=accuracy_score(y_train, dtc.predict(x_train))\n",
    "print(\"TrainingAccuracy:\",round(Training_accuracy_dtc*100,2),\"%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfea8377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GaussianNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "nb=GaussianNB()\n",
    "nb.fit(x_train,y_train)\n",
    "y_pred_nb=nb.predict(x_test)\n",
    "#print(\"predicted data is:\")\n",
    "#print(y_pred_nb)\n",
    "#print(\"actual data is:\")\n",
    "#print(np.array(y_test))\n",
    "\n",
    "print(f\"The the NB model is {accuracy_score(y_pred_nb,y_test)*100}% accurate\")\n",
    "print(classification_report(y_pred_nb,y_test))\n",
    "#Build confusion matrix\n",
    "# Calculate the confusion matrix\n",
    "\n",
    "cf_matrix = confusion_matrix(y_true=y_test, y_pred=y_pred_nb)\n",
    "#cf_matrix=confusion_matrix(y_test,y_pred, labels=['0','1'])\n",
    "#cf_matrix = confusion_matrix(y, y_pred)\n",
    "#print(cf_matrix)\n",
    "#sns.heatmap(cf_matrix, annot=True)\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, fmt='.2%')\n",
    "a_nb = accuracy_score(y_pred_nb,y_test) \n",
    "p_nb= precision_score(y_test, y_pred_nb, average = 'weighted')\n",
    "r_nb = recall_score(y_test, y_pred_nb, average = 'weighted')\n",
    "print(\"Accuracy:\",round(a_nb*100,2),\"%\")\n",
    "print(\"Precision:\",round(p_nb*100,2),\"%\")\n",
    "print(\"Recall:\",round(r_nb*100,2),\"%\")\n",
    "f1_nb = f1_score(y_test, y_pred_nb)\n",
    "print(\"f1_score:\",round(f1_nb*100,2),\"%\")\n",
    "Training_accuracy_nb=accuracy_score(y_train, nb.predict(x_train))\n",
    "print(\"TrainingAccuracy:\",round(Training_accuracy_nb*100,2),\"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d635565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(solver='liblinear', random_state=0)\n",
    "lr.fit(x_train,y_train)\n",
    "y_pred_lr=lr.predict(x_test)\n",
    "accuracy_score(y_pred_lr,y_test)\n",
    "print(classification_report(y_pred_lr,y_test))\n",
    "cf_matrix = confusion_matrix(y_true=y_test, y_pred=y_pred_lr)\n",
    "\n",
    "#print(cf_matrix)\n",
    "#sns.heatmap(cf_matrix, annot=True)\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, fmt='.2%')\n",
    "a_lr = accuracy_score(y_pred_lr,y_test) \n",
    "p_lr = precision_score(y_pred_lr,y_test, average = 'weighted')\n",
    "r_lr = recall_score(y_pred_lr,y_test, average = 'weighted')\n",
    "print(\"Accuracy:\",round(a_lr*100,2),\"%\")\n",
    "print(\"Precision:\",round(p_lr*100,2),\"%\")\n",
    "print(\"Recall:\",round(r_lr*100,2),\"%\")\n",
    "f1_lr = f1_score(y_test, y_pred_lr)\n",
    "print(\"f1_score:\",round(f1_lr*100,2),\"%\")\n",
    "Training_accuracy_lr=accuracy_score(y_train, lr.predict(x_train))\n",
    "print(\"TrainingAccuracy:\",round(Training_accuracy_lr*100,2),\"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1db1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score,f1_score\n",
    "knn=KNeighborsClassifier(n_neighbors=7)\n",
    "#knn=KNeighborsClassifier(n_neighbors=1, weights='uniform', algorithm='auto', leaf_size=30, p=2,metric='minkowski', metric_params=None, n_jobs=None)\n",
    "knn.fit(x_train,y_train)\n",
    "y_pred_knn=knn.predict(x_test)\n",
    "#y_pred_knn\n",
    "\n",
    "accuracy_score(y_pred_knn,y_test)\n",
    "print(classification_report(y_pred_knn,y_test))\n",
    "#Build confusion matrix\n",
    "# Calculate the confusion matrix\n",
    "\n",
    "cf_matrix = confusion_matrix(y_true=y_test, y_pred=y_pred_knn)\n",
    "\n",
    "#print(cf_matrix)\n",
    "#sns.heatmap(cf_matrix, annot=True)\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, fmt='.2%')\n",
    "a_knn = accuracy_score(y_pred_knn,y_test) \n",
    "p_knn = precision_score(y_pred_knn,y_test, average = 'weighted')\n",
    "r_knn = recall_score(y_pred_knn,y_test, average = 'weighted')\n",
    "print(\"Accuracy:\",round(a_knn*100,2),\"%\")\n",
    "print(\"Precision:\",round(p_knn*100,2),\"%\")\n",
    "print(\"Recall:\",round(r_knn*100,2),\"%\")\n",
    "f1_knn = f1_score(y_test, y_pred_knn)\n",
    "print(\"f1_score:\",round(f1_knn*100,2),\"%\")\n",
    "Training_accuracy_knn=accuracy_score(y_train, knn.predict(x_train))\n",
    "print(\"TrainingAccuracy:\",round(Training_accuracy_knn*100,2),\"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632c31be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestClassifier\n",
    "print(\"RandomForestClassifier\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#model_rf=RandomForestClassifier()\n",
    "model_rf=RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, \n",
    "min_samples_split=12, min_samples_leaf=5, min_weight_fraction_leaf=0.0, max_features='log2',\n",
    "max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None,   random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "model_rf.fit(x_train,y_train)\n",
    "y_pred_rf=model_rf.predict(x_test)\n",
    "y_pred_rf\n",
    "acc_rf=accuracy_score(y_pred_rf,y_test)\n",
    "print(classification_report(y_pred_rf,y_test))\n",
    "\n",
    "cf_matrix = confusion_matrix(y_true=y_test, y_pred=y_pred_rf)\n",
    "\n",
    "#print(cf_matrix)\n",
    "#sns.heatmap(cf_matrix, annot=True)\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, fmt='.2%')\n",
    "a_rf = accuracy_score(y_pred_rf,y_test) \n",
    "p_rf = precision_score(y_pred_rf,y_test, average = 'weighted')\n",
    "r_rf = recall_score(y_pred_rf,y_test, average = 'weighted')\n",
    "print(\"Accuracy:\",round(a_rf*100,2),\"%\")\n",
    "print(\"Precision:\",round(p_rf*100,2),\"%\")\n",
    "print(\"Recall:\",round(r_rf*100,2),\"%\")\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "print(\"f1_score:\",round(f1_rf*100,2),\"%\")\n",
    "Training_accuracy_rf=accuracy_score(y_train, model_rf.predict(x_train))\n",
    "print(\"TrainingAccuracy:\",round(Training_accuracy_rf*100,2),\"%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bd1701",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "voting_3_classifiers = VotingClassifier(estimators=[('GaussianNB', nb),('Decison Tree',dtc),\n",
    "                                                    ('KNN',knn),('logistic_regression',lr)], \n",
    "                                        voting='soft')\n",
    "voting_3_classifiers.fit(x_train,y_train)\n",
    "voting_predictions_soft = voting_3_classifiers.predict(x_test)\n",
    "print('Accuracy of voting_3_classifiers = ', accuracy_score(y_test, voting_predictions_soft)*100)\n",
    "a_voting_soft = accuracy_score(y_test, voting_predictions_soft)\n",
    "p_voting_soft = precision_score(y_test, voting_predictions_soft, average = 'weighted')\n",
    "r_voting_soft = recall_score(y_test, voting_predictions_soft, average = 'weighted')\n",
    "print(\"Accuracy:\",round(a_voting_soft*100,2),\"%\")\n",
    "print(\"Precision:\",round(p_voting_soft*100,2),\"%\")\n",
    "print(\"Recall:\",round(r_voting_soft*100,2),\"%\")\n",
    "f1_voting_soft = f1_score(y_test, voting_predictions_soft,average='weighted')\n",
    "print(\"f1_score:\",round(f1_voting_soft*100,2),\"%\")\n",
    "Training_accuracy_soft=accuracy_score(y_train, voting_3_classifiers.predict(x_train))\n",
    "print(\"TrainingAccuracy:\",round(Training_accuracy_soft*100,2),\"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5ecade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "voting_3_classifiers = VotingClassifier(estimators=[ ('GaussianNB', nb),('Decison Tree',dtc),\n",
    "                                                    ('KNN',knn),('logistic_regression',lr)], \n",
    "                                        voting='hard')\n",
    "voting_3_classifiers.fit(x_train,y_train)\n",
    "voting_predictions_hard = voting_3_classifiers.predict(x_test)\n",
    "print('Accuracy of voting_3_classifiers = ', accuracy_score(y_test, voting_predictions_hard)*100)\n",
    "a_voting_hard = accuracy_score(y_test, voting_predictions_hard)\n",
    "p_voting_hard = precision_score(y_test, voting_predictions_hard, average = 'weighted')\n",
    "r_voting_hard = recall_score(y_test, voting_predictions_hard, average = 'weighted')\n",
    "print(\"Accuracy:\",round(a_voting_hard*100,2),\"%\")\n",
    "print(\"Precision:\",round(p_voting_hard*100,2),\"%\")\n",
    "print(\"Recall:\",round(r_voting_hard*100,2),\"%\")\n",
    "f1_voting_hard = f1_score(y_test, voting_predictions_hard)\n",
    "print(\"f1_score:\",round(f1_voting_hard*100,2),\"%\")\n",
    "Training_accuracy_voting_3_classifiers=accuracy_score(y_test, voting_3_classifiers.predict(x_test))\n",
    "print(\"TrainingAccuracy:\",round(Training_accuracy_voting_3_classifiers*100,2),\"%\")\n",
    "#Build confusion matrix\n",
    "# Calculate the confusion matrix\n",
    "\n",
    "cf_matrix = confusion_matrix(y_true=y_test, y_pred=voting_predictions_hard)\n",
    "#cf_matrix=confusion_matrix(y_test,y_pred, labels=['0','1'])\n",
    "#cf_matrix = confusion_matrix(y, y_pred)\n",
    "print(cf_matrix)\n",
    "#sns.heatmap(cf_matrix, annot=True)\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, fmt='.2%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a2637a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# set width of bar\n",
    "barWidth = 0.15\n",
    "fig = plt.subplots(figsize =(30, 15))\n",
    " \n",
    "# set height of bar\n",
    "Accuracy = [a_rf*100, a_dtc*100, a_nb*100, a_knn*100, a_lr*100, a_voting_soft*100, a_voting_hard*100]\n",
    "Precision = [p_rf*100, p_dtc*100, p_nb*100, p_knn*100, p_lr*100, p_voting_soft*100, p_voting_hard*100]\n",
    "Recall = [r_rf*100, r_dtc*100, r_nb*100, r_knn*100, r_lr*100, r_voting_soft*100, r_voting_hard*100]\n",
    "f1_score = [f1_rf*100, f1_dtc*100, f1_nb*100, f1_knn*100, f1_lr*100, f1_voting_soft*100, f1_voting_hard*100]\n",
    " \n",
    "# Set position of bar on X axis\n",
    "br1 = np.arange(len(Accuracy))\n",
    "br2 = [x + barWidth for x in br1]\n",
    "br3 = [x + barWidth for x in br2]\n",
    "br4 = [x + barWidth for x in br3]\n",
    " \n",
    "# Make the plot\n",
    "plt.bar(br1, Accuracy, color ='r', width = barWidth,\n",
    "        edgecolor ='grey', label ='Accuracy')\n",
    "plt.bar(br2, Precision, color ='g', width = barWidth,\n",
    "        edgecolor ='grey', label ='Precision')\n",
    "plt.bar(br3, Recall, color ='b', width = barWidth,\n",
    "        edgecolor ='grey', label ='Recall')\n",
    "plt.bar(br4, f1_score, color ='c', width = barWidth,\n",
    "        edgecolor ='grey', label ='f1_score')\n",
    " \n",
    "# Adding Xticks\n",
    "plt.xlabel('Classifier', fontweight ='bold', fontsize = 15)\n",
    "plt.ylabel('Values %', fontweight ='bold', fontsize = 15)\n",
    "plt.xticks([r + barWidth for r in range(len(Accuracy))],\n",
    "        ['RandomForest', 'DecisionTree', 'GaussianNB', 'KNeighbors', 'LogisticRegression', 'SoftVoting', 'HardVoting'])\n",
    " \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
